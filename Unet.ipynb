{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"understanding_cloud_organization/sample_submission.csv\")\n",
    "train = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Image_name'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train['Label_name'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train.drop('Image_Label',axis=1,inplace=True)\n",
    "train = train.pivot('Image_name','Label_name','EncodedPixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "img=mpimg.imread('./understanding_cloud_organization/train_images_320/009e2f3.jpg')\n",
    "img2=mpimg.imread('./understanding_cloud_organization/train_images_320_Black_Fish_Gravel_Sugar_Flower/009e2f3.jpg')\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(img2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import MoveAxis, Normalize01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import Compose, DenseTarget\n",
    "from transformations import MoveAxis, Normalize01\n",
    "from customdatasets2 import SegmentationDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from customdatasets import make_mask\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'understanding_cloud_organization'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'train_images_320')  \n",
    "true_inputs = []\n",
    "true_targets = []\n",
    "\n",
    "shape = (320, 480)\n",
    "\n",
    "\n",
    "for input in inputs:\n",
    "    img_name = str(input).split('/')[-1]\n",
    "    array_input = imread(input)\n",
    "    true_inputs.append(array_input)\n",
    "  #  true_inputs.append(np.fliplr(array_input))\n",
    " #   true_inputs.append(np.flipud(array_input))\n",
    "    mask = make_mask(df, img_name, shape)\n",
    "    true_targets.append(mask)\n",
    " #   true_targets.append(np.fliplr(mask))\n",
    "  #  true_targets.append(np.flipud(mask))\n",
    "    \n",
    "# training transformations and augmentations\n",
    "transforms = Compose([\n",
    "    DenseTarget(),\n",
    "    Normalize01(),\n",
    "    MoveAxis(),\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    true_inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    true_targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "    \n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms)\n",
    "\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=4,\n",
    "                                 shuffle=False)\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=4,\n",
    "                                   shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': dataloader_training,\n",
    "    'val': dataloader_validation\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader_training))\n",
    "w, z = next(iter(dataloader_training))\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\n",
    "print(f'y = min: {y.min()}; max: {y.max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import helper\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "x, y = next(iter(dataloader_training))\n",
    "\n",
    "true_inputs = x\n",
    "\n",
    "true_labels = y\n",
    "print(true_labels[0].numpy().shape)\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy()\n",
    "    inp = np.moveaxis(inp, -1, 0)\n",
    "    inp = np.moveaxis(inp, -1, 0)\n",
    "    input_asarray = np.clip(inp, 0, 1)\n",
    "    input_asarray = (input_asarray * 255).astype(np.uint8)\n",
    "    return input_asarray\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in true_inputs]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x.cpu(), \"xD\") for x in true_labels]\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(input_images_rgb[0])\n",
    "axarr[1].imshow(target_masks_rgb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unet import *\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=4,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).cuda()\n",
    "\n",
    "x = torch.randn(size=(1, 3, 320, 480), dtype=torch.float32).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "print(f'Out: {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary = summary(model, (3, 320, 480))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1920\n",
    "\n",
    "\n",
    "def compute_max_depth(shape, max_depth=10, print_out=True):\n",
    "    shapes = []\n",
    "    shapes.append(shape)\n",
    "    for level in range(1, max_depth):\n",
    "        if shape % 2 ** level == 0 and shape / 2 ** level > 1:\n",
    "            shapes.append(shape / 2 ** level)\n",
    "            if print_out:\n",
    "                print(f'Level {level}: {shape / 2 ** level}')\n",
    "        else:\n",
    "            if print_out:\n",
    "                print(f'Max-level: {level - 1}')\n",
    "            break\n",
    "\n",
    "    return shapes\n",
    "\n",
    "\n",
    "out = compute_max_depth(shape, print_out=True, max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 10\n",
    "high = 512\n",
    "depth = 8\n",
    "\n",
    "\n",
    "def compute_possible_shapes(low, high, depth):\n",
    "    possible_shapes = {}\n",
    "    for shape in range(low, high + 1):\n",
    "        shapes = compute_max_depth(shape,\n",
    "                                   max_depth=depth,\n",
    "                                   print_out=False)\n",
    "        if len(shapes) == depth:\n",
    "            possible_shapes[shape] = shapes\n",
    "\n",
    "    return possible_shapes\n",
    "possible_shapes = compute_possible_shapes(low, high, depth)\n",
    "possible_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN ET RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=2,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  'cloud.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import *\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.show(training_losses, validation_losses)\n",
    "print(training_losses)\n",
    "print(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "fig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pathlib\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'understanding_cloud_organization'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'train_images_320')\n",
    "targets = get_filenames_of_path(root / 'train_images_320_Black_Fish_Gravel_Sugar_Flower')\n",
    "\n",
    "model.eval()   # Set model to evaluate mode\n",
    "\n",
    "train_size = 0.8  # 80:20 split\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_dataset = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "test_loader = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=2,\n",
    "                                 shuffle=False)\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=2,\n",
    "                                   shuffle=False)\n",
    "        \n",
    "x, y = next(iter(dataloader_training))\n",
    "true_inputs = x.to(device)\n",
    "true_labels = y.to(device)\n",
    "\n",
    "pred = model(true_inputs).cpu()\n",
    "out_pred = torch.softmax(pred, dim=1).detach()\n",
    "\n",
    "\n",
    "true_inputs = true_inputs.cpu()\n",
    "true_labels = true_labels.cpu()\n",
    "\n",
    "\n",
    "\n",
    "import torchvision.utils\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy()\n",
    "    inp = np.moveaxis(inp, -1, 0)\n",
    "    inp = np.moveaxis(inp, -1, 0)\n",
    "    input_asarray = np.clip(inp, 0, 1)\n",
    "    input_asarray = (input_asarray * 255).astype(np.uint8)\n",
    "    return input_asarray\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [reverse_transform(x) for x in true_inputs]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x.cpu(), \"xD\") for x in true_labels]\n",
    "\n",
    "pred_rgb = [helper.masks_to_colorimg(x, \"xD\") for x in out_pred]\n",
    "\n",
    "f, axarr = plt.subplots(2,3)\n",
    "axarr[0][0].imshow(input_images_rgb[0])\n",
    "axarr[0][1].imshow(target_masks_rgb[0])\n",
    "axarr[0][2].imshow(pred_rgb[0])\n",
    "axarr[1][0].imshow(input_images_rgb[1])\n",
    "axarr[1][1].imshow(target_masks_rgb[1])\n",
    "axarr[1][2].imshow(pred_rgb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
