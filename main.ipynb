{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"understanding_cloud_organization/sample_submission.csv\")\n",
    "train = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Image_name'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train['Label_name'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train.drop('Image_Label',axis=1,inplace=True)\n",
    "train = train.pivot('Image_name','Label_name','EncodedPixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "img=mpimg.imread('./understanding_cloud_organization/train_images_320/009e2f3.jpg')\n",
    "img2=mpimg.imread('./understanding_cloud_organization/train_images_320_Black_Fish_Gravel_Sugar_Flower/009e2f3.jpg')\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(img2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import MoveAxis, Normalize01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import Compose, DenseTarget\n",
    "from transformations import MoveAxis, Normalize01\n",
    "from customdatasets import SegmentationDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'understanding_cloud_organization'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'train_images_320')\n",
    "targets = get_filenames_of_path(root / 'train_images_320_Black_Fish_Gravel_Sugar_Flower')\n",
    "    \n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms = Compose([\n",
    "    DenseTarget(),\n",
    "    Normalize01(),\n",
    "    MoveAxis(),\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False)\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 480, 4)\n",
      "[0. 1.]\n",
      "x = shape: torch.Size([1, 3, 320, 480]); type: torch.float32\n",
      "x = min: 0.0; max: 1.0\n",
      "y = shape: torch.Size([1, 4, 320, 480]); class: tensor([0, 1]); type: torch.int64\n",
      "y = min: 0; max: 1\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dataloader_training))\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\n",
    "print(f'y = min: {y.min()}; max: {y.max()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out: torch.Size([1, 4, 320, 480])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unet import *\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=4,\n",
    "             n_blocks=2,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).cuda()\n",
    "\n",
    "x = torch.randn(size=(1, 3, 320, 480), dtype=torch.float32).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "print(f'Out: {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 320, 480]             896\n",
      "              ReLU-2         [-1, 32, 320, 480]               0\n",
      "       BatchNorm2d-3         [-1, 32, 320, 480]              64\n",
      "            Conv2d-4         [-1, 32, 320, 480]           9,248\n",
      "              ReLU-5         [-1, 32, 320, 480]               0\n",
      "       BatchNorm2d-6         [-1, 32, 320, 480]              64\n",
      "         MaxPool2d-7         [-1, 32, 160, 240]               0\n",
      "         DownBlock-8  [[-1, 32, 160, 240], [-1, 32, 320, 480]]               0\n",
      "            Conv2d-9         [-1, 64, 160, 240]          18,496\n",
      "             ReLU-10         [-1, 64, 160, 240]               0\n",
      "      BatchNorm2d-11         [-1, 64, 160, 240]             128\n",
      "           Conv2d-12         [-1, 64, 160, 240]          36,928\n",
      "             ReLU-13         [-1, 64, 160, 240]               0\n",
      "      BatchNorm2d-14         [-1, 64, 160, 240]             128\n",
      "        DownBlock-15  [[-1, 64, 160, 240], [-1, 64, 160, 240]]               0\n",
      "  ConvTranspose2d-16         [-1, 32, 320, 480]           8,224\n",
      "             ReLU-17         [-1, 32, 320, 480]               0\n",
      "      BatchNorm2d-18         [-1, 32, 320, 480]              64\n",
      "      Concatenate-19         [-1, 64, 320, 480]               0\n",
      "           Conv2d-20         [-1, 32, 320, 480]          18,464\n",
      "             ReLU-21         [-1, 32, 320, 480]               0\n",
      "      BatchNorm2d-22         [-1, 32, 320, 480]              64\n",
      "           Conv2d-23         [-1, 32, 320, 480]           9,248\n",
      "             ReLU-24         [-1, 32, 320, 480]               0\n",
      "      BatchNorm2d-25         [-1, 32, 320, 480]              64\n",
      "          UpBlock-26         [-1, 32, 320, 480]               0\n",
      "           Conv2d-27          [-1, 4, 320, 480]             132\n",
      "================================================================\n",
      "Total params: 102,212\n",
      "Trainable params: 102,212\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.76\n",
      "Forward/backward pass size (MB): 92159198.44\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 92159200.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary = summary(model, (3, 320, 480))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1920\n",
    "\n",
    "\n",
    "def compute_max_depth(shape, max_depth=10, print_out=True):\n",
    "    shapes = []\n",
    "    shapes.append(shape)\n",
    "    for level in range(1, max_depth):\n",
    "        if shape % 2 ** level == 0 and shape / 2 ** level > 1:\n",
    "            shapes.append(shape / 2 ** level)\n",
    "            if print_out:\n",
    "                print(f'Level {level}: {shape / 2 ** level}')\n",
    "        else:\n",
    "            if print_out:\n",
    "                print(f'Max-level: {level - 1}')\n",
    "            break\n",
    "\n",
    "    return shapes\n",
    "\n",
    "\n",
    "out = compute_max_depth(shape, print_out=True, max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 10\n",
    "high = 512\n",
    "depth = 8\n",
    "\n",
    "\n",
    "def compute_possible_shapes(low, high, depth):\n",
    "    possible_shapes = {}\n",
    "    for shape in range(low, high + 1):\n",
    "        shapes = compute_max_depth(shape,\n",
    "                                   max_depth=depth,\n",
    "                                   print_out=False)\n",
    "        if len(shapes) == depth:\n",
    "            possible_shapes[shape] = shapes\n",
    "\n",
    "    return possible_shapes\n",
    "possible_shapes = compute_possible_shapes(low, high, depth)\n",
    "possible_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN ET RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ebde4c21648a8abfa2837f1cd802d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Progress', max=4.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fqsfdsqfqsfsqfsfqsfq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af924b6e268049848daaadaef0f6224d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=4436.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 480, 4)\n",
      "[0. 1.]\n",
      "tensor([[[[-6.3622e-01,  1.2339e-02, -3.4365e-01,  ...,  3.7109e-01,\n",
      "           -9.9831e-01, -1.1909e+00],\n",
      "          [ 7.8182e-01, -9.2661e-01,  2.4257e-01,  ...,  5.4175e-01,\n",
      "           -3.6212e-01, -2.9613e-01],\n",
      "          [-1.6041e+00, -4.9536e-01,  1.5249e+00,  ..., -3.0436e-01,\n",
      "            1.5707e+00,  3.1424e-01],\n",
      "          ...,\n",
      "          [-5.7945e-01,  1.3291e+00, -7.2450e-01,  ..., -1.2481e+00,\n",
      "            2.9970e-01, -5.9813e-02],\n",
      "          [-6.7875e-01,  1.9287e+00,  1.5276e-01,  ..., -2.2289e+00,\n",
      "           -1.0078e-01, -1.6999e-01],\n",
      "          [ 4.3849e-01,  5.8851e-01,  3.8648e-01,  ...,  1.0841e+00,\n",
      "           -5.9309e-01,  8.5957e-01]],\n",
      "\n",
      "         [[ 8.3933e-02,  1.0792e+00,  4.7205e-01,  ...,  1.7602e-01,\n",
      "           -9.3773e-01, -1.6699e-01],\n",
      "          [-6.9396e-01, -8.7370e-01, -5.8831e-01,  ...,  2.6851e-01,\n",
      "            4.3158e-02,  8.4035e-02],\n",
      "          [ 5.5070e-01,  5.4432e-01,  1.4168e+00,  ...,  5.3776e-01,\n",
      "            9.7221e-01, -8.3009e-02],\n",
      "          ...,\n",
      "          [ 9.5769e-01,  1.9342e+00,  7.3821e-01,  ..., -2.2097e-01,\n",
      "            8.3076e-01, -3.7906e-01],\n",
      "          [ 3.8158e-01,  3.4073e-01, -6.1208e-01,  ..., -2.6538e+00,\n",
      "           -2.5104e-01, -1.8714e-01],\n",
      "          [ 4.3661e-01, -9.0969e-02, -2.4103e-02,  ...,  3.4325e-01,\n",
      "           -8.0130e-01, -7.0810e-01]],\n",
      "\n",
      "         [[ 1.8873e-03, -9.9598e-01, -2.1061e-01,  ..., -4.5561e-01,\n",
      "           -1.3190e-01, -4.4916e-01],\n",
      "          [ 7.1803e-01,  2.3399e+00, -3.0837e-01,  ...,  3.2103e-01,\n",
      "           -1.8655e+00, -1.5552e+00],\n",
      "          [ 2.3930e+00,  3.7495e-02, -9.2567e-01,  ..., -1.5422e+00,\n",
      "           -1.1364e+00, -1.7600e+00],\n",
      "          ...,\n",
      "          [ 5.3199e-01,  1.1152e-01, -1.7563e+00,  ..., -1.6820e+00,\n",
      "            2.0171e-01, -7.5912e-01],\n",
      "          [-5.0590e-01, -2.7956e-01, -7.7162e-02,  ..., -1.7526e+00,\n",
      "            1.4415e-01, -1.1263e+00],\n",
      "          [-1.1439e+00, -1.7737e+00, -1.2271e+00,  ..., -6.7409e-02,\n",
      "           -7.4731e-01, -2.2887e-01]],\n",
      "\n",
      "         [[ 8.6560e-01,  9.0588e-01,  3.1077e-01,  ..., -3.6448e-01,\n",
      "            2.4789e-01,  4.7835e-02],\n",
      "          [-1.8973e-02,  1.3890e-02,  6.9150e-01,  ..., -2.4827e+00,\n",
      "           -5.9837e-01, -6.7620e-01],\n",
      "          [-1.3251e+00, -5.7228e-01, -9.0541e-01,  ...,  1.0452e+00,\n",
      "           -1.3613e+00,  8.0122e-01],\n",
      "          ...,\n",
      "          [ 2.9022e-01, -5.5762e-01, -5.6164e-01,  ..., -1.6460e+00,\n",
      "           -1.3070e+00, -9.0364e-01],\n",
      "          [-1.1300e+00,  1.2064e+00, -2.4711e-01,  ...,  4.1844e-01,\n",
      "            3.1163e-01,  3.9729e-01],\n",
      "          [ 1.1867e-01,  1.6838e-01,  1.1950e+00,  ..., -7.7758e-01,\n",
      "           -1.1799e+00,  1.4510e+00]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3ec2b4b51e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_rates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TraitementDeNuages/train.py\u001b[0m in \u001b[0;36mrun_trainer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fqsfdsqfqsfsqfsfqsfq\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;34m\"\"\"Training block\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34m\"\"\"Validation block\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TraitementDeNuages/train.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# one forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "from train import Trainer\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=4,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  'cloud.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import *\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.show(training_losses, validation_losses)\n",
    "print(training_losses)\n",
    "print(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "fig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
