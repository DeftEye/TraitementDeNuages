{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"understanding_cloud_organization/sample_submission.csv\")\n",
    "train = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Image_name'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train['Label_name'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train.drop('Image_Label',axis=1,inplace=True)\n",
    "train = train.pivot('Image_name','Label_name','EncodedPixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "df = pd.DataFrame(columns = ['Name' , 'Image'])\n",
    "directory = \"understanding_cloud_organization/train_images_320\"\n",
    "\n",
    "for image_name in os.listdir(directory) :\n",
    "    if image_name.split(\".\")[1]=='jpg':\n",
    "        im = imread(directory + '/' + image_name)\n",
    "        df = df.append({'Name' : image_name.split(\".\")[0], 'Image': im}, ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mask = pd.DataFrame(columns = ['Name' , 'Image'])\n",
    "directory = \"understanding_cloud_organization/train_images_320_Black_Fish_Gravel_Sugar_Flower\"\n",
    "\n",
    "for image_name in os.listdir(directory) :\n",
    "    if image_name.split(\".\")[1]=='jpg':\n",
    "        im = imread(directory + '/' + image_name)\n",
    "        df_mask = df_mask.append({'Name' : image_name.split(\".\")[0], 'Image': im}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1 augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5546it [05:47, 15.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i, im in tqdm(enumerate(df[\"Image\"])) :\n",
    "    image_name = df[\"Name\"].iloc[i]\n",
    "    for da in range(1, 8+1) :\n",
    "        transform = augm.Compose([\n",
    "            augm.RandomRotate90(p=1), # Rotate 90째\n",
    "            augm.HorizontalFlip(p=1), # Horizontal Flip, to keep brain structure (don't do vertical flip)\n",
    "            augm.CLAHE(p=1), # Apply Contrast Limited Adaptive Histogram Equalization to the input image\n",
    "            augm.ColorJitter(p=1), # Randomly changes the brightness, contrast, and saturation of an image\n",
    "            augm.OpticalDistortion(p=1),\n",
    "            augm.GridDistortion(p=1),\n",
    "            augm.HueSaturationValue(p=1) # Randomly change hue, saturation and value of the input image\n",
    "        ])\n",
    "        transformed = transform(image=im)\n",
    "        transformed_image = transformed[\"image\"]    \n",
    "        df = df.append({'Name': image_name + \"_da\" + str(da), 'Image': transformed_image}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5546it [06:25, 14.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, im in tqdm(enumerate(df_mask[\"Image\"])) :\n",
    "    mask_name= df_mask[\"Name\"].iloc[i]\n",
    "    for da in range(1, 8+1) :\n",
    "        transform = augm.Compose([\n",
    "            augm.RandomRotate90(p=1), # Rotate 90째\n",
    "            augm.HorizontalFlip(p=1), # Horizontal Flip, to keep brain structure (don't do vertical flip)\n",
    "            augm.CLAHE(p=1), # Apply Contrast Limited Adaptive Histogram Equalization to the input image\n",
    "            augm.ColorJitter(p=1), # Randomly changes the brightness, contrast, and saturation of an image\n",
    "            augm.OpticalDistortion(p=1),\n",
    "            augm.GridDistortion(p=1),\n",
    "            augm.HueSaturationValue(p=1) # Randomly change hue, saturation and value of the input image\n",
    "        ])\n",
    "        transformed= transform(image=im)  \n",
    "        transformed_mask = transformed[\"image\"]\n",
    "        df_mask = df_mask.append({'Name': mask_name + \"_da\" + str(da), 'Image': transformed_mask}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2 Augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as augm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5546it [02:35, 35.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, im in tqdm(enumerate(df[\"Image\"])) :\n",
    "    image_name = df[\"Name\"].iloc[i]\n",
    "    transformrot90 = augm.RandomRotate90(p=1) # Rotate 90째 \n",
    "    transformHorizontalFlip= augm.HorizontalFlip(p=1) # Horizontal Flip\n",
    "    transfDistorsion = augm.OpticalDistortion(p=1)\n",
    "    transfOpticalDistortion= augm.OpticalDistortion(p=1)\n",
    "\n",
    "    transformed1 = transformrot90(image=im)\n",
    "    transformed2 = transformHorizontalFlip(image=im)\n",
    "    transformed3=transfDistorsion(image=im)\n",
    "    transformed4=transfOpticalDistortion(image=im)\n",
    "\n",
    "    transformed_image1 = transformed1[\"image\"]    \n",
    "    transformed_image2 = transformed2[\"image\"]  \n",
    "    transformed_image3 = transformed3[\"image\"]  \n",
    "    transformed_image4 = transformed4[\"image\"]  \n",
    "\n",
    "    df = df.append({'Name': image_name + \"_transformrot90\" , 'Image': transformed_image1}, ignore_index=True)\n",
    "    df = df.append({'Name': image_name + \"_transformHorizontalFlip\", 'Image': transformed_image2}, ignore_index=True)\n",
    "    df = df.append({'Name': image_name + \"_transfDistorsion\" , 'Image': transformed_image3}, ignore_index=True)\n",
    "    df = df.append({'Name': image_name + \"_transfOpticalDistortion\" , 'Image': transformed_image4}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5546it [01:00, 91.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, im in tqdm(enumerate(df_mask[\"Image\"])) :\n",
    "    image_name = df_mask[\"Name\"].iloc[i]\n",
    "    transformrot90 = augm.RandomRotate90(p=1) # Rotate 90째 \n",
    "    transformHorizontalFlip= augm.HorizontalFlip(p=1) # Horizontal Flip\n",
    "    transfDistorsion = augm.OpticalDistortion(p=1)\n",
    "    transfOpticalDistortion= augm.OpticalDistortion(p=1)\n",
    "\n",
    "    transformed1 = transformrot90(image=im)\n",
    "    transformed2 = transformHorizontalFlip(image=im)\n",
    "    transformed3=transfDistorsion(image=im)\n",
    "    transformed4=transfOpticalDistortion(image=im)\n",
    "\n",
    "    transformed_image1 = transformed1[\"image\"]    \n",
    "    transformed_image2 = transformed2[\"image\"]  \n",
    "    transformed_image3 = transformed3[\"image\"]  \n",
    "    transformed_image4 = transformed4[\"image\"]  \n",
    "\n",
    "    df_mask = df_mask.append({'Name': image_name + \"_transformrot90\" , 'Image': transformed_image1}, ignore_index=True)\n",
    "    df_mask = df_mask.append({'Name': image_name + \"_transformHorizontalFlip\", 'Image': transformed_image2}, ignore_index=True)\n",
    "    df_mask = df_mask.append({'Name': image_name + \"_transfDistorsion\" , 'Image': transformed_image3}, ignore_index=True)\n",
    "    df_mask = df_mask.append({'Name': image_name + \"_transfOpticalDistortion\" , 'Image': transformed_image4}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "save = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27730it [06:15, 73.80it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if(save):\n",
    "    for i, img in tqdm(enumerate(df[\"Image\"])):\n",
    "        im = Image.fromarray(img)\n",
    "        im.save(os.path.join('understanding_cloud_organization/augmented_data2/', df[\"Name\"].iloc[i] + \".jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27730it [04:14, 109.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if(save):\n",
    "    for i, img in tqdm(enumerate(df_mask[\"Image\"])):\n",
    "        im = Image.fromarray(img)\n",
    "        im.save(os.path.join('understanding_cloud_organization/augmented_data2_mask/', df_mask[\"Name\"].iloc[i] + \".jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affichage Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "img=mpimg.imread('./understanding_cloud_organization/train_images_320/009e2f3.jpg')\n",
    "img2=mpimg.imread('./understanding_cloud_organization/train_images_320_Black_Fish_Gravel_Sugar_Flower/009e2f3.jpg')\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img)\n",
    "axarr[1].imshow(img2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import MoveAxis, Normalize01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import Compose, DenseTarget\n",
    "from transformations import MoveAxis, Normalize01\n",
    "from customdatasets import SegmentationDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'understanding_cloud_organization'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'train_images_320')\n",
    "targets = get_filenames_of_path(root / 'train_images_320_Black_Fish_Gravel_Sugar_Flower')\n",
    "    \n",
    "\n",
    "# training transformations and augmentations\n",
    "transforms = Compose([\n",
    "    DenseTarget(),\n",
    "    Normalize01(),\n",
    "    MoveAxis(),\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms)\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False)\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader_training))\n",
    "print(f'x = shape: {x.shape}; type: {x.dtype}')\n",
    "print(f'x = min: {x.min()}; max: {x.max()}')\n",
    "print(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\n",
    "print(f'y = min: {y.min()}; max: {y.max()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unet import *\n",
    "model = UNet(in_channels=3,\n",
    "             out_channels=4,\n",
    "             n_blocks=2,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2).cuda()\n",
    "\n",
    "x = torch.randn(size=(1, 3, 320, 480), dtype=torch.float32).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "print(f'Out: {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary = summary(model, (3, 320, 480))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1920\n",
    "\n",
    "\n",
    "def compute_max_depth(shape, max_depth=10, print_out=True):\n",
    "    shapes = []\n",
    "    shapes.append(shape)\n",
    "    for level in range(1, max_depth):\n",
    "        if shape % 2 ** level == 0 and shape / 2 ** level > 1:\n",
    "            shapes.append(shape / 2 ** level)\n",
    "            if print_out:\n",
    "                print(f'Level {level}: {shape / 2 ** level}')\n",
    "        else:\n",
    "            if print_out:\n",
    "                print(f'Max-level: {level - 1}')\n",
    "            break\n",
    "\n",
    "    return shapes\n",
    "\n",
    "\n",
    "out = compute_max_depth(shape, print_out=True, max_depth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 10\n",
    "high = 512\n",
    "depth = 8\n",
    "\n",
    "\n",
    "def compute_possible_shapes(low, high, depth):\n",
    "    possible_shapes = {}\n",
    "    for shape in range(low, high + 1):\n",
    "        shapes = compute_max_depth(shape,\n",
    "                                   max_depth=depth,\n",
    "                                   print_out=False)\n",
    "        if len(shapes) == depth:\n",
    "            possible_shapes[shape] = shapes\n",
    "\n",
    "    return possible_shapes\n",
    "possible_shapes = compute_possible_shapes(low, high, depth)\n",
    "possible_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN ET RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "\n",
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    torch.device('cpu')\n",
    "\n",
    "# criterion\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  device=device,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=dataloader_training,\n",
    "                  validation_DataLoader=dataloader_validation,\n",
    "                  lr_scheduler=None,\n",
    "                  epochs=4,\n",
    "                  epoch=0,\n",
    "                  notebook=True)\n",
    "\n",
    "# start training\n",
    "training_losses, validation_losses, lr_rates = trainer.run_trainer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  'cloud.pt'\n",
    "torch.save(model.state_dict(), pathlib.Path.cwd() / model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_rate_finder import *\n",
    "lrf = LearningRateFinder(model, criterion, optimizer, device)\n",
    "lrf.fit(dataloader_training, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.show(training_losses, validation_losses)\n",
    "print(training_losses)\n",
    "print(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual import plot_training\n",
    "fig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
