{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformations import Compose, DenseTarget\n",
    "from transformations import MoveAxis, Normalize01\n",
    "from customdatasets2 import SegmentationDataSet\n",
    "from torch.utils.data import DataLoader\n",
    "from customdatasets import make_mask\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")\n",
    "\n",
    "# root directory\n",
    "root = pathlib.Path.cwd() / 'understanding_cloud_organization'\n",
    "def get_filenames_of_path(path: pathlib.Path, ext: str = '*'):\n",
    "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n",
    "    filenames = [file for file in path.glob(ext) if file.is_file()]\n",
    "    return filenames\n",
    "\n",
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'train_images_320')  \n",
    "true_inputs = []\n",
    "true_targets = []\n",
    "\n",
    "shape = (320, 480)\n",
    "\n",
    "\n",
    "for input in inputs:\n",
    "    img_name = str(input).split('/')[-1]\n",
    "    array_input = imread(input)\n",
    "    true_inputs.append(array_input)\n",
    "    true_inputs.append(np.fliplr(array_input))\n",
    "    true_inputs.append(np.flipud(array_input))\n",
    "    mask = make_mask(df, img_name, shape)\n",
    "    true_targets.append(mask)\n",
    "    true_targets.append(np.fliplr(mask))\n",
    "    true_targets.append(np.flipud(mask))\n",
    "    \n",
    "# training transformations and augmentations\n",
    "transforms = Compose([\n",
    "    DenseTarget(),\n",
    "    Normalize01(),\n",
    "    MoveAxis(),\n",
    "])\n",
    "\n",
    "# random seed\n",
    "random_seed = 42\n",
    "\n",
    "# split dataset into training set and validation set\n",
    "train_size = 0.8  # 80:20 split\n",
    "\n",
    "inputs_train, inputs_valid = train_test_split(\n",
    "    true_inputs,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "targets_train, targets_valid = train_test_split(\n",
    "    true_targets,\n",
    "    random_state=random_seed,\n",
    "    train_size=train_size,\n",
    "    shuffle=True)\n",
    "\n",
    "# dataset training\n",
    "dataset_train = SegmentationDataSet(inputs=inputs_train,\n",
    "                                    targets=targets_train,\n",
    "                                    transform=transforms)\n",
    "\n",
    "    \n",
    "\n",
    "# dataset validation\n",
    "dataset_valid = SegmentationDataSet(inputs=inputs_valid,\n",
    "                                    targets=targets_valid,\n",
    "                                    transform=transforms)\n",
    "\n",
    "\n",
    "# dataloader training\n",
    "dataloader_training = DataLoader(dataset=dataset_train,\n",
    "                                 batch_size=4,\n",
    "                                 shuffle=False)\n",
    "# dataloader validation\n",
    "dataloader_validation = DataLoader(dataset=dataset_valid,\n",
    "                                   batch_size=4,\n",
    "                                   shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': dataloader_training,\n",
    "    'val': dataloader_validation\n",
    "} \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission = pd.read_csv(\"understanding_cloud_organization/sample_submission.csv\")\n",
    "train = pd.read_csv(\"understanding_cloud_organization/train_320.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Image_name'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "train['Label_name'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
    "train.drop('Image_Label',axis=1,inplace=True)\n",
    "train = train.pivot('Image_name','Label_name','EncodedPixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label_name</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Gravel</th>\n",
       "      <th>Sugar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0011165.jpg</th>\n",
       "      <td>14154 214 14474 214 14794 214 15114 214 15434 ...</td>\n",
       "      <td>71125 229 71445 229 71765 229 72085 229 72405 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002be4f.jpg</th>\n",
       "      <td>12484 201 12804 201 13124 201 13444 201 13764 ...</td>\n",
       "      <td>70282 119 70602 119 70922 119 71242 119 71562 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3589 80 3909 80 4229 80 4549 80 4869 80 5189 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0031ae9.jpg</th>\n",
       "      <td>484 157 804 157 1124 157 1444 157 1764 157 208...</td>\n",
       "      <td>469 161 789 161 1109 161 1429 161 1749 161 203...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34600 89 34920 89 35240 89 35560 89 35880 89 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0035239.jpg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5444 106 5764 106 6084 106 6404 106 6724 106 7...</td>\n",
       "      <td>3750 87 4070 87 4390 87 4710 87 5030 87 5350 8...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003994e.jpg</th>\n",
       "      <td>123970 3 123975 1 123977 16 124282 1 124285 3 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18679 96 18999 96 19319 96 19639 96 19959 96 2...</td>\n",
       "      <td>1604 112 1924 112 2244 112 2564 112 2884 112 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label_name                                                Fish  \\\n",
       "Image_name                                                       \n",
       "0011165.jpg  14154 214 14474 214 14794 214 15114 214 15434 ...   \n",
       "002be4f.jpg  12484 201 12804 201 13124 201 13444 201 13764 ...   \n",
       "0031ae9.jpg  484 157 804 157 1124 157 1444 157 1764 157 208...   \n",
       "0035239.jpg                                                NaN   \n",
       "003994e.jpg  123970 3 123975 1 123977 16 124282 1 124285 3 ...   \n",
       "\n",
       "Label_name                                              Flower  \\\n",
       "Image_name                                                       \n",
       "0011165.jpg  71125 229 71445 229 71765 229 72085 229 72405 ...   \n",
       "002be4f.jpg  70282 119 70602 119 70922 119 71242 119 71562 ...   \n",
       "0031ae9.jpg  469 161 789 161 1109 161 1429 161 1749 161 203...   \n",
       "0035239.jpg  5444 106 5764 106 6084 106 6404 106 6724 106 7...   \n",
       "003994e.jpg                                                NaN   \n",
       "\n",
       "Label_name                                              Gravel  \\\n",
       "Image_name                                                       \n",
       "0011165.jpg                                                NaN   \n",
       "002be4f.jpg                                                NaN   \n",
       "0031ae9.jpg                                                NaN   \n",
       "0035239.jpg  3750 87 4070 87 4390 87 4710 87 5030 87 5350 8...   \n",
       "003994e.jpg  18679 96 18999 96 19319 96 19639 96 19959 96 2...   \n",
       "\n",
       "Label_name                                               Sugar  \n",
       "Image_name                                                      \n",
       "0011165.jpg                                                NaN  \n",
       "002be4f.jpg  3589 80 3909 80 4229 80 4549 80 4869 80 5189 8...  \n",
       "0031ae9.jpg  34600 89 34920 89 35240 89 35560 89 35880 89 3...  \n",
       "0035239.jpg                                                NaN  \n",
       "003994e.jpg  1604 112 1924 112 2244 112 2564 112 2884 112 3...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5547 images in train dataset\n",
      "There are 1987 images in test dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'understanding_cloud_organization'\n",
    "n_train = len(os.listdir(f'{path}/train_images_350'))\n",
    "n_test = len(os.listdir(f'{path}/test_images_350'))\n",
    "print(f'There are {n_train} images in train dataset')\n",
    "print(f'There are {n_test} images in test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Image_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Image_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-90a191f0ea67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Image_name'"
     ]
    }
   ],
   "source": [
    "train['Image_name'].apply(lambda x: x.split('_')[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 320, 480]           1,792\n",
      "              ReLU-2         [-1, 64, 320, 480]               0\n",
      "            Conv2d-3         [-1, 64, 320, 480]          36,928\n",
      "              ReLU-4         [-1, 64, 320, 480]               0\n",
      "            Conv2d-5         [-1, 64, 160, 240]           9,408\n",
      "            Conv2d-6         [-1, 64, 160, 240]           9,408\n",
      "       BatchNorm2d-7         [-1, 64, 160, 240]             128\n",
      "       BatchNorm2d-8         [-1, 64, 160, 240]             128\n",
      "              ReLU-9         [-1, 64, 160, 240]               0\n",
      "             ReLU-10         [-1, 64, 160, 240]               0\n",
      "        MaxPool2d-11          [-1, 64, 80, 120]               0\n",
      "        MaxPool2d-12          [-1, 64, 80, 120]               0\n",
      "           Conv2d-13          [-1, 64, 80, 120]          36,864\n",
      "           Conv2d-14          [-1, 64, 80, 120]          36,864\n",
      "      BatchNorm2d-15          [-1, 64, 80, 120]             128\n",
      "      BatchNorm2d-16          [-1, 64, 80, 120]             128\n",
      "             ReLU-17          [-1, 64, 80, 120]               0\n",
      "             ReLU-18          [-1, 64, 80, 120]               0\n",
      "           Conv2d-19          [-1, 64, 80, 120]          36,864\n",
      "           Conv2d-20          [-1, 64, 80, 120]          36,864\n",
      "      BatchNorm2d-21          [-1, 64, 80, 120]             128\n",
      "      BatchNorm2d-22          [-1, 64, 80, 120]             128\n",
      "             ReLU-23          [-1, 64, 80, 120]               0\n",
      "             ReLU-24          [-1, 64, 80, 120]               0\n",
      "       BasicBlock-25          [-1, 64, 80, 120]               0\n",
      "       BasicBlock-26          [-1, 64, 80, 120]               0\n",
      "           Conv2d-27          [-1, 64, 80, 120]          36,864\n",
      "           Conv2d-28          [-1, 64, 80, 120]          36,864\n",
      "      BatchNorm2d-29          [-1, 64, 80, 120]             128\n",
      "      BatchNorm2d-30          [-1, 64, 80, 120]             128\n",
      "             ReLU-31          [-1, 64, 80, 120]               0\n",
      "             ReLU-32          [-1, 64, 80, 120]               0\n",
      "           Conv2d-33          [-1, 64, 80, 120]          36,864\n",
      "           Conv2d-34          [-1, 64, 80, 120]          36,864\n",
      "      BatchNorm2d-35          [-1, 64, 80, 120]             128\n",
      "      BatchNorm2d-36          [-1, 64, 80, 120]             128\n",
      "             ReLU-37          [-1, 64, 80, 120]               0\n",
      "             ReLU-38          [-1, 64, 80, 120]               0\n",
      "       BasicBlock-39          [-1, 64, 80, 120]               0\n",
      "       BasicBlock-40          [-1, 64, 80, 120]               0\n",
      "           Conv2d-41          [-1, 128, 40, 60]          73,728\n",
      "           Conv2d-42          [-1, 128, 40, 60]          73,728\n",
      "      BatchNorm2d-43          [-1, 128, 40, 60]             256\n",
      "      BatchNorm2d-44          [-1, 128, 40, 60]             256\n",
      "             ReLU-45          [-1, 128, 40, 60]               0\n",
      "             ReLU-46          [-1, 128, 40, 60]               0\n",
      "           Conv2d-47          [-1, 128, 40, 60]         147,456\n",
      "           Conv2d-48          [-1, 128, 40, 60]         147,456\n",
      "      BatchNorm2d-49          [-1, 128, 40, 60]             256\n",
      "      BatchNorm2d-50          [-1, 128, 40, 60]             256\n",
      "           Conv2d-51          [-1, 128, 40, 60]           8,192\n",
      "           Conv2d-52          [-1, 128, 40, 60]           8,192\n",
      "      BatchNorm2d-53          [-1, 128, 40, 60]             256\n",
      "      BatchNorm2d-54          [-1, 128, 40, 60]             256\n",
      "             ReLU-55          [-1, 128, 40, 60]               0\n",
      "             ReLU-56          [-1, 128, 40, 60]               0\n",
      "       BasicBlock-57          [-1, 128, 40, 60]               0\n",
      "       BasicBlock-58          [-1, 128, 40, 60]               0\n",
      "           Conv2d-59          [-1, 128, 40, 60]         147,456\n",
      "           Conv2d-60          [-1, 128, 40, 60]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 40, 60]             256\n",
      "      BatchNorm2d-62          [-1, 128, 40, 60]             256\n",
      "             ReLU-63          [-1, 128, 40, 60]               0\n",
      "             ReLU-64          [-1, 128, 40, 60]               0\n",
      "           Conv2d-65          [-1, 128, 40, 60]         147,456\n",
      "           Conv2d-66          [-1, 128, 40, 60]         147,456\n",
      "      BatchNorm2d-67          [-1, 128, 40, 60]             256\n",
      "      BatchNorm2d-68          [-1, 128, 40, 60]             256\n",
      "             ReLU-69          [-1, 128, 40, 60]               0\n",
      "             ReLU-70          [-1, 128, 40, 60]               0\n",
      "       BasicBlock-71          [-1, 128, 40, 60]               0\n",
      "       BasicBlock-72          [-1, 128, 40, 60]               0\n",
      "           Conv2d-73          [-1, 256, 20, 30]         294,912\n",
      "           Conv2d-74          [-1, 256, 20, 30]         294,912\n",
      "      BatchNorm2d-75          [-1, 256, 20, 30]             512\n",
      "      BatchNorm2d-76          [-1, 256, 20, 30]             512\n",
      "             ReLU-77          [-1, 256, 20, 30]               0\n",
      "             ReLU-78          [-1, 256, 20, 30]               0\n",
      "           Conv2d-79          [-1, 256, 20, 30]         589,824\n",
      "           Conv2d-80          [-1, 256, 20, 30]         589,824\n",
      "      BatchNorm2d-81          [-1, 256, 20, 30]             512\n",
      "      BatchNorm2d-82          [-1, 256, 20, 30]             512\n",
      "           Conv2d-83          [-1, 256, 20, 30]          32,768\n",
      "           Conv2d-84          [-1, 256, 20, 30]          32,768\n",
      "      BatchNorm2d-85          [-1, 256, 20, 30]             512\n",
      "      BatchNorm2d-86          [-1, 256, 20, 30]             512\n",
      "             ReLU-87          [-1, 256, 20, 30]               0\n",
      "             ReLU-88          [-1, 256, 20, 30]               0\n",
      "       BasicBlock-89          [-1, 256, 20, 30]               0\n",
      "       BasicBlock-90          [-1, 256, 20, 30]               0\n",
      "           Conv2d-91          [-1, 256, 20, 30]         589,824\n",
      "           Conv2d-92          [-1, 256, 20, 30]         589,824\n",
      "      BatchNorm2d-93          [-1, 256, 20, 30]             512\n",
      "      BatchNorm2d-94          [-1, 256, 20, 30]             512\n",
      "             ReLU-95          [-1, 256, 20, 30]               0\n",
      "             ReLU-96          [-1, 256, 20, 30]               0\n",
      "           Conv2d-97          [-1, 256, 20, 30]         589,824\n",
      "           Conv2d-98          [-1, 256, 20, 30]         589,824\n",
      "      BatchNorm2d-99          [-1, 256, 20, 30]             512\n",
      "     BatchNorm2d-100          [-1, 256, 20, 30]             512\n",
      "            ReLU-101          [-1, 256, 20, 30]               0\n",
      "            ReLU-102          [-1, 256, 20, 30]               0\n",
      "      BasicBlock-103          [-1, 256, 20, 30]               0\n",
      "      BasicBlock-104          [-1, 256, 20, 30]               0\n",
      "          Conv2d-105          [-1, 256, 20, 30]          65,792\n",
      "            ReLU-106          [-1, 256, 20, 30]               0\n",
      "        Upsample-107          [-1, 256, 40, 60]               0\n",
      "          Conv2d-108          [-1, 128, 40, 60]          16,512\n",
      "            ReLU-109          [-1, 128, 40, 60]               0\n",
      "          Conv2d-110          [-1, 256, 40, 60]         884,992\n",
      "            ReLU-111          [-1, 256, 40, 60]               0\n",
      "        Upsample-112         [-1, 256, 80, 120]               0\n",
      "          Conv2d-113          [-1, 64, 80, 120]           4,160\n",
      "            ReLU-114          [-1, 64, 80, 120]               0\n",
      "          Conv2d-115         [-1, 256, 80, 120]         737,536\n",
      "            ReLU-116         [-1, 256, 80, 120]               0\n",
      "        Upsample-117        [-1, 256, 160, 240]               0\n",
      "          Conv2d-118         [-1, 64, 160, 240]           4,160\n",
      "            ReLU-119         [-1, 64, 160, 240]               0\n",
      "          Conv2d-120        [-1, 128, 160, 240]         368,768\n",
      "            ReLU-121        [-1, 128, 160, 240]               0\n",
      "        Upsample-122        [-1, 128, 320, 480]               0\n",
      "          Conv2d-123         [-1, 64, 320, 480]         110,656\n",
      "            ReLU-124         [-1, 64, 320, 480]               0\n",
      "          Conv2d-125          [-1, 4, 320, 480]             260\n",
      "================================================================\n",
      "Total params: 7,797,124\n",
      "Trainable params: 7,797,124\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.76\n",
      "Forward/backward pass size (MB): 1244.53\n",
      "Params size (MB): 29.74\n",
      "Estimated Total Size (MB): 1276.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from resnet_unet import ResNetUNet \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNetUNet(n_class=4)\n",
    "model = model.to(device)\n",
    "\n",
    "# check keras-like model summary using torchsummary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 320, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import dice_loss\n",
    "\n",
    "def calc_loss(pred, target, metrics, bce_weight=1):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
    "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
    "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/6\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.329540, dice: 0.808422, loss: 0.329540\n",
      "val: bce: 0.289273, dice: 0.767563, loss: 0.289273\n",
      "saving best model\n",
      "11m 3s\n",
      "Epoch 1/6\n",
      "----------\n",
      "LR 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_class = 4\n",
    "model = ResNetUNet(num_class).to(device)\n",
    "\n",
    "# freeze backbone layers\n",
    "#for l in model.base_layers:\n",
    "#    for param in l.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pixels = []\n",
    "loaders = {\"infer\": valid_loader}\n",
    "runner.infer(\n",
    "    model=model,\n",
    "    loaders=loaders,\n",
    "    callbacks=[\n",
    "        CheckpointCallback(\n",
    "            resume=f\"{logdir}/checkpoints/best.pth\"),\n",
    "        InferCallback()\n",
    "    ],\n",
    ")\n",
    "valid_masks = []\n",
    "probabilities = np.zeros((2220, 350, 525))\n",
    "for i, (batch, output) in enumerate(tqdm.tqdm(zip(\n",
    "        valid_dataset, runner.callbacks[0].predictions[\"logits\"]))):\n",
    "    image, mask = batch\n",
    "    for m in mask:\n",
    "        if m.shape != (350, 525):\n",
    "            m = cv2.resize(m, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "        valid_masks.append(m)\n",
    "\n",
    "    for j, probability in enumerate(output):\n",
    "        if probability.shape != (350, 525):\n",
    "            probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "        probabilities[i * 4 + j, :, :] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'probabilities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6e60d2485dd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'probabilities' is not defined"
     ]
    }
   ],
   "source": [
    "class_params = {}\n",
    "for class_id in range(4):\n",
    "    print(class_id)\n",
    "    attempts = []\n",
    "    for t in range(0, 100, 5):\n",
    "        t /= 100\n",
    "        for ms in [0, 100, 1200, 5000, 10000]:\n",
    "            masks = []\n",
    "            for i in range(class_id, len(probabilities), 4):\n",
    "                probability = probabilities[i]\n",
    "                predict, num_predict = post_process(sigmoid(probability), t, ms)\n",
    "                masks.append(predict)\n",
    "\n",
    "            d = []\n",
    "            for i, j in zip(masks, valid_masks[class_id::4]):\n",
    "                if (i.sum() == 0) & (j.sum() == 0):\n",
    "                    d.append(1)\n",
    "                else:\n",
    "                    d.append(dice(i, j))\n",
    "\n",
    "            attempts.append((t, ms, np.mean(d)))\n",
    "\n",
    "    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
    "\n",
    "\n",
    "    attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
    "    print(attempts_df.head())\n",
    "    best_threshold = attempts_df['threshold'].values[0]\n",
    "    best_size = attempts_df['size'].values[0]\n",
    "    \n",
    "    class_params[class_id] = (best_threshold, best_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3a501ce909bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threshold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattempts_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Threshold and min size vs dice for one of the classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x='threshold', y='dice', hue='size', data=attempts_df);\n",
    "plt.title('Threshold and min size vs dice for one of the classes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2d42b8a0f42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m for i, (input, output) in enumerate(zip(\n\u001b[0;32m----> 2\u001b[0;31m         valid_dataset, runner.callbacks[0].predictions[\"logits\"])):\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage_vis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (input, output) in enumerate(zip(\n",
    "        valid_dataset, runner.callbacks[0].predictions[\"logits\"])):\n",
    "    image, mask = input\n",
    "        \n",
    "    image_vis = image.transpose(1, 2, 0)\n",
    "    mask = mask.astype('uint8').transpose(1, 2, 0)\n",
    "    pr_mask = np.zeros((350, 525, 4))\n",
    "    for j in range(4):\n",
    "        probability = cv2.resize(output.transpose(1, 2, 0)[:, :, j], dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "        pr_mask[:, :, j], _ = post_process(sigmoid(probability), class_params[j][0], class_params[j][1])\n",
    "    #pr_mask = (sigmoid(output) > best_threshold).astype('uint8').transpose(1, 2, 0)\n",
    "    \n",
    "        \n",
    "    visualize_with_raw(image=image_vis, mask=pr_mask, original_image=image_vis, original_mask=mask, raw_image=image_vis, raw_mask=output.transpose(1, 2, 0))\n",
    "    \n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0c934370c873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CloudDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ef75ca3a6292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validation_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CloudDataset' is not defined"
     ]
    }
   ],
   "source": [
    "test_dataset = CloudDataset(df=sub, datatype='test', img_ids=test_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "loaders = {\"test\": test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-59648e0382b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoded_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrunner_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_pixels = []\n",
    "image_id = 0\n",
    "for i, test_batch in enumerate(tqdm.tqdm(loaders['test'])):\n",
    "    runner_out = runner.predict_batch({\"features\": test_batch[0].cuda()})['logits']\n",
    "    for i, batch in enumerate(runner_out):\n",
    "        for probability in batch:\n",
    "            \n",
    "            probability = probability.cpu().detach().numpy()\n",
    "            if probability.shape != (350, 525):\n",
    "                probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "            predict, num_predict = post_process(sigmoid(probability), class_params[image_id % 4][0], class_params[image_id % 4][1])\n",
    "            if num_predict == 0:\n",
    "                encoded_pixels.append('')\n",
    "            else:\n",
    "                r = mask2rle(predict)\n",
    "                encoded_pixels.append(r)\n",
    "            image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c7f60695fb6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EncodedPixels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_pixels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image_Label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EncodedPixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub['EncodedPixels'] = encoded_pixels\n",
    "sub.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
